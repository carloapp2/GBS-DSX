# Working with Spark SQL
## Introduction:

[<img src="https://raw.githubusercontent.com/Davin-IBM/Proof-of-Technology/master/DSX/images/DSX.png" height="150"/>](http://datascience.ibm.com/) [<img src="https://raw.githubusercontent.com/Davin-IBM/Proof-of-Technology/master/DSX/images/jupyter.png" height="150"/>](http://jupyter.org/index.html)

In this lab, you will use IBM's Data Science Experience (DSX) to create a Jupyter IPython notebook to examine the basic principles of Spark SQL.

## Objectives:

Upon completing the lab, you will know how to:

1. Create a Spark SQL Context
1. Create and use Spark SQL queries
1. Connect to an external database and read data 

## Instructions:

### Step 1.  Log into your [DSX](http://datascience.ibm.com/) account, then select `View All Projects`, then select the project you created at the beginning of this proof of technology.

> <img src="https://raw.githubusercontent.com/jpatter/Proof-of-Technology/master/DSX/Lab-1/images/DSX-open-project.png"/>

### Step 2.  Click the `add notebooks` link in the top right of your project pane.

> <img src="https://raw.githubusercontent.com/Davin-IBM/Proof-of-Technology/master/DSX/Lab-1/images/DSX-add-notebook.png"/>

### Step 3.  Create the notebook.

> <img src="https://github.com/jpatter/SparkPOT/blob/master/Lab-2/images/SparkPOT-CreateNotebook-Lab2.PNG"/>

1. Click the `From URL` tab under `Create Notebook`.
1. Give the notebook a name in the `Name` field, for example `Spark Lab-2` and optionally you can give it a description.
1. In the Notebook URL field, use `https://github.com/jpatter/SparkPOT/blob/master/Lab-2/Lab2Student.ipynb`.
1. Ensure that there is a `Spark Service` selected, then click the `Create Notebook` button on the bottom right of the screen.

### Step 4.  Follow the instructions in the notebook.

> <img src="https://github.com/jpatter/SparkPOT/blob/master/Lab-2/images/SparkPOT-Lab2.PNG"/>

